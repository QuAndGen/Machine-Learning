import os

# Set environment variables for spark setup via python script

os.environ['HADOOP_HOME']="path of winutils" # example C:/hadoop/bin
os.environ['JAVA_HOME']='C:/Program Files/Java/jre1.8.0_221/'
os.environ['SPARK_HOME']='C:/spark/spark-2.4.4-bin-hadoop2.7/'

os.environ['PYSPARK_PYTHON'] = 'C:/Program Files/Anaconda3/python.exe'

os.environ['PYSPARK_DRIVER_PYTHON']= 'C:/Program Files/Anaconda3/Scripts/jupyter.exe'

os.environ['PYSPARK_DRIVER_PYTHON_OPTS']='notebook'

# delete environment variables for spark setup via python script

del os.environ['HADOOP_HOME']
del os.environ['JAVA_HOME']

del os.environ['SPARK_HOME']

del os.environ['PYSPARK_PYTHON']

del os.environ['PYSPARK_DRIVER_PYTHON']

del os.environ['PYSPARK_DRIVER_PYTHON_OPTS']
del os.environ['PYSPARK_SUBMIT_ARGS']

# get the list of environment variable
os.environ
